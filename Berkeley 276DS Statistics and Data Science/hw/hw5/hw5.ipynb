{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639def6e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847c863",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Homework 5 <br><br> Neural networks for time series forecasting </center></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaedd05",
   "metadata": {},
   "source": [
    "In this homework we will build a model to forecast the intensity of traffic flow on a freeway over the coming 24 hours, based on measurements of traffic flow intensity over the past six hours. The data was obtained from Caltrans' Performance Measurement System ([PeMS](https://pems.dot.ca.gov/)). This site archives 5-minute average flow and speed measurements taken from sensors embedded in the pavement, at approximately 1-mile intervals, on freeways across the state. We will focus on measurements from a particular sensor, taken between January 2018 and October 2019. \n",
    "\n",
    "We will compare three neural network architectures: a dense neural network with multiple input and output channels, a simple recurrent neural network, and an LSTM network. We will use Keras and Tensorflow to build and train these models. Use `pip` to install these packages in your Python environment.\n",
    "\n",
    "``` \n",
    "pip install tensorflow\n",
    "pip install keras\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb695b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:09.707550Z",
     "iopub.status.busy": "2023-11-12T00:47:09.707182Z",
     "iopub.status.idle": "2023-11-12T00:47:11.492575Z",
     "shell.execute_reply": "2023-11-12T00:47:11.492078Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Flatten\n",
    "keras.utils.set_random_seed(812)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4dfcd",
   "metadata": {},
   "source": [
    "# 0. Load the data\n",
    "\n",
    "Use `pd.read_csv` to load the CSV file `'traffic_flows.csv'` data into a pandas DataFrame called `rawdata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac52d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.494746Z",
     "iopub.status.busy": "2023-11-12T00:47:11.494462Z",
     "iopub.status.idle": "2023-11-12T00:47:11.506640Z",
     "shell.execute_reply": "2023-11-12T00:47:11.506205Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawdata = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a4617",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447a0f7",
   "metadata": {},
   "source": [
    "Notice that we have a total of 13,980 data samples, ranging from January 1st, 2018 to October 26th, 2019. The following table tells us that the `DateAndTime` column is string-valued, while the `Total Flow` column contains numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2131b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.512620Z",
     "iopub.status.busy": "2023-11-12T00:47:11.512453Z",
     "iopub.status.idle": "2023-11-12T00:47:11.601576Z",
     "shell.execute_reply": "2023-11-12T00:47:11.600990Z"
    }
   },
   "outputs": [],
   "source": [
    "rawdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95439d89",
   "metadata": {},
   "source": [
    "## 1. Convert the DateAndTime column to type Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59017765",
   "metadata": {},
   "source": [
    "To enable pandas' time series features, we must convert the `DateAndTime` information from a strings into `Timestamp` objects. Use pandas' [`to_datetime`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) method to do this. Pass the `DateAndTime` column of `rawdata` into this method, and store the result in a new column called 'DateAndTimeTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb11c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.603402Z",
     "iopub.status.busy": "2023-11-12T00:47:11.603232Z",
     "iopub.status.idle": "2023-11-12T00:47:11.634486Z",
     "shell.execute_reply": "2023-11-12T00:47:11.634097Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawdata['DateAndTimeTS'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f98ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.635957Z",
     "iopub.status.busy": "2023-11-12T00:47:11.635794Z",
     "iopub.status.idle": "2023-11-12T00:47:11.642119Z",
     "shell.execute_reply": "2023-11-12T00:47:11.641722Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9d358",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817c03d",
   "metadata": {},
   "source": [
    "## 2. Use the `DateAndTimeTS` as the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e6885",
   "metadata": {},
   "source": [
    "The [`set_index`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html) method of `rawdata` returns a new table with the given column as its index. Pass the string 'DataAndTimeTS' into this method and store the result in `data1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba12d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.648409Z",
     "iopub.status.busy": "2023-11-12T00:47:11.648219Z",
     "iopub.status.idle": "2023-11-12T00:47:11.651768Z",
     "shell.execute_reply": "2023-11-12T00:47:11.651462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d811e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.653087Z",
     "iopub.status.busy": "2023-11-12T00:47:11.652946Z",
     "iopub.status.idle": "2023-11-12T00:47:11.657208Z",
     "shell.execute_reply": "2023-11-12T00:47:11.656878Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a34f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0ab72",
   "metadata": {},
   "source": [
    "# 3. Drop the `DateAndTime` column\n",
    "\n",
    "The `DateAndTime` column is now superfluous. Use the [`drop`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) method applied to `data1` with the `columns` argument to remove this column. Store the result in `data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65943feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.662912Z",
     "iopub.status.busy": "2023-11-12T00:47:11.662775Z",
     "iopub.status.idle": "2023-11-12T00:47:11.665852Z",
     "shell.execute_reply": "2023-11-12T00:47:11.665555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c84bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.667208Z",
     "iopub.status.busy": "2023-11-12T00:47:11.667065Z",
     "iopub.status.idle": "2023-11-12T00:47:11.670780Z",
     "shell.execute_reply": "2023-11-12T00:47:11.670469Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591507c7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88125281",
   "metadata": {},
   "source": [
    "Pandas attaches matplotlib plotting functions to its DataFrame objects. Hence we can call `plot` directly from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf7478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.676463Z",
     "iopub.status.busy": "2023-11-12T00:47:11.676220Z",
     "iopub.status.idle": "2023-11-12T00:47:11.923131Z",
     "shell.execute_reply": "2023-11-12T00:47:11.922501Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.plot(figsize=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5f311",
   "metadata": {},
   "source": [
    "As a side note, you can add pan/zoom functionality to your plots by installing the `ipympl` package (`pip install ipympl`) and adding the line `%matplotlib widget` to your code:\n",
    "\n",
    "``` python \n",
    "%matplotlib widget\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(data2,'.-')\n",
    "plt.grid()\n",
    "```\n",
    "Here is what we see if we then zoom in to the plot:\n",
    "\n",
    "<img src=\"f1.png\" />\n",
    "\n",
    "We can also pass in the x and y limits to pandas' plot method. Notice below that the x-limits can be conveniently specified as dates (this is one of those aformentioned feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d1839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:11.924960Z",
     "iopub.status.busy": "2023-11-12T00:47:11.924725Z",
     "iopub.status.idle": "2023-11-12T00:47:12.106230Z",
     "shell.execute_reply": "2023-11-12T00:47:12.105694Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.plot(figsize=(10,4),\n",
    "           xlim=('2018-02-16','2018-03-16'),\n",
    "           style='.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872eaf1",
   "metadata": {},
   "source": [
    "There are indeed quite a few days missing in February and March 2018. If these gaps were small, we might consider filling them with linear interpolation -- effectively filling in the above plot with round markers along the long lines. However this would likely confuse the model-training procedure. Instead we will simply ignore these gaps. The model-training procedure will still be confused by the suddem jumps in the flow, however perhaps less than with interpolation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5426bd",
   "metadata": {},
   "source": [
    "# 4. Training and testing datasets\n",
    "\n",
    "We will use 80\\% of the data for training and 20\\% for testing. The dataset has 13,980 hourly samples. Since we are building a time-series forecasting model, it is important that the test dataset follow the training dataset in time. Create a training dataset (`data_train`) by selecting the first 11,184 samples (`ind_split`) from `data2`, and a testing dataset with the remaining samples. \n",
    "\n",
    "**Hint**: [`data2.iloc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6250ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.109118Z",
     "iopub.status.busy": "2023-11-12T00:47:12.108627Z",
     "iopub.status.idle": "2023-11-12T00:47:12.112013Z",
     "shell.execute_reply": "2023-11-12T00:47:12.111640Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Nraw = data2.shape[0]\n",
    "train_portion = 0.8\n",
    "ind_split = int(0.8*Nraw)\n",
    "print(Nraw, ind_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a1f2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.113967Z",
     "iopub.status.busy": "2023-11-12T00:47:12.113779Z",
     "iopub.status.idle": "2023-11-12T00:47:12.117466Z",
     "shell.execute_reply": "2023-11-12T00:47:12.117080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = data2.iloc[...]\n",
    "data_test = data2.iloc[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340754b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb7bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.125371Z",
     "iopub.status.busy": "2023-11-12T00:47:12.125055Z",
     "iopub.status.idle": "2023-11-12T00:47:12.399379Z",
     "shell.execute_reply": "2023-11-12T00:47:12.398754Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(data_train,label='training data')\n",
    "plt.plot(data_test,label='test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5205cc",
   "metadata": {},
   "source": [
    "# 5. Normalize the data\n",
    "\n",
    "The performance of neural network models is typically enhanced by normalizing the inputs and outputs. We will use scikit-learn's `StandardScaler` to do this. \n",
    "\n",
    "When preprocessing data, such as we are doing now, it is important that the test data be treated identically to the training data. This means that the same scaling factors should be applied to the test data samples as were applied to the training data. This was achieved in lab 5 with scikit-learn's `Pipeline` object. Here we will achieve the same by scaling the test data with `StandardScaler` that was fit using the training data.\n",
    "\n",
    "**Hint** The `fit` and `transform` methods of the `StandardScaler` must receive a matrix-like object -- that is, one with two dimensions. This means that we must add an empty dimension to our one-dimensional flow vector. To acheive this, you can use the `reshape` method as follows:\n",
    "\n",
    "`data_train['Flow'].values.reshape(-1, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e82cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.401422Z",
     "iopub.status.busy": "2023-11-12T00:47:12.401238Z",
     "iopub.status.idle": "2023-11-12T00:47:12.406609Z",
     "shell.execute_reply": "2023-11-12T00:47:12.406287Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(...)\n",
    "\n",
    "data_train_scaled = scaler.transform(...)\n",
    "data_test_scaled = scaler.transform(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d3a9d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4941e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Organize the data into past and future snippets of flow values.\n",
    "\n",
    "Write a function that recevies a scaled dataset `d` (`data_train_scaled` or `data_test_scaled`) and creates inputs and output matrices `X` and `y` suitable for model training.\n",
    "\n",
    "The figure below provides an illustration. Each sample $(x_i,y_i)$ consists of `Np=6` hours of \"past\" data in $x_i$ and `Nf=24` hours of \"future\" data in $y_i$. If the input sequence `d` has length `L`, then there will be `N=L-Np-Nf` such samples. Hence the dimensions of `X` and `y` should be `(N,Nh)` and `(N,Nf)` respectively.\n",
    "\n",
    "<img src='f2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f3662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.422722Z",
     "iopub.status.busy": "2023-11-12T00:47:12.422547Z",
     "iopub.status.idle": "2023-11-12T00:47:12.427108Z",
     "shell.execute_reply": "2023-11-12T00:47:12.426751Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Np = 6\n",
    "Nf = 24\n",
    "\n",
    "def make_samples(d):\n",
    "\n",
    "    L = d.shape[0]\n",
    "    N = ...\n",
    "\n",
    "    X = np.empty(...)\n",
    "    y = np.empty(...)\n",
    "\n",
    "    for i in range(N):\n",
    "        X[i,:] = d[...,0]\n",
    "        y[i,:] = d[...,0]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25058318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.428998Z",
     "iopub.status.busy": "2023-11-12T00:47:12.428711Z",
     "iopub.status.idle": "2023-11-12T00:47:12.443685Z",
     "shell.execute_reply": "2023-11-12T00:47:12.443364Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xtrain, ytrain = make_samples(data_train_scaled)\n",
    "Xtest, ytest = make_samples(data_test_scaled)\n",
    "\n",
    "Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1372668",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d2984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.459388Z",
     "iopub.status.busy": "2023-11-12T00:47:12.459125Z",
     "iopub.status.idle": "2023-11-12T00:47:12.571792Z",
     "shell.execute_reply": "2023-11-12T00:47:12.571291Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 40\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(np.arange(0,Np),Xtrain[i],'ro-',linewidth=2,label='x_i')\n",
    "plt.plot(np.arange(Np,Np+Nf),ytrain[i],'go-',linewidth=2,label='y_i')\n",
    "plt.legend()\n",
    "plt.grid(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80dff98",
   "metadata": {},
   "source": [
    "# 7. Add an empty dimension to the training and test datasets to satisfy a Tensorflow requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36740167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.573835Z",
     "iopub.status.busy": "2023-11-12T00:47:12.573600Z",
     "iopub.status.idle": "2023-11-12T00:47:12.577848Z",
     "shell.execute_reply": "2023-11-12T00:47:12.577470Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xtrain_e = Xtrain[:,:,np.newaxis]\n",
    "ytrain_e = ...\n",
    "Xtest_e = ...\n",
    "ytest_e = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3d40a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b0740",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. Train a dense neural network\n",
    "\n",
    "A schematic of our model is shown below.\n",
    "\n",
    "<img src='f3.png'>\n",
    "\n",
    "The model has a single dense hidden layer with 5 neurons (a.k.a. \"units\") and a `relu` activation function. The output layer has `Nf=24` units -- one  for each of the outputs of the model. Keras requires that we add a `Flatten()` layer to process the input (I'm not sure why). The final model code looks like this:\n",
    "\n",
    "``` python\n",
    "model_dense = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(5, activation=\"relu\"),\n",
    "    Dense(Nf)\n",
    "])\n",
    "```\n",
    "\n",
    "Enter this code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7b8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.590678Z",
     "iopub.status.busy": "2023-11-12T00:47:12.590542Z",
     "iopub.status.idle": "2023-11-12T00:47:12.621396Z",
     "shell.execute_reply": "2023-11-12T00:47:12.620873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dense = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb695be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0ecf5",
   "metadata": {},
   "source": [
    "Next we compile and train this model. The compilation step was not required in scikit-learn. It is used in Keras to configure the model object according to the hardware characteristics of the computing environment. For example, it will prepare the model to be trained using GPUs if you have configured Keras to do this and have the appropriate hardware. \n",
    "\n",
    "The `compile` method must receive the chosen loss function to be minimized, and the numerical optimization method to use. We will use minimize the mean squared error using the `adam` optimizer (an improved version of stochastic gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57cb76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.631945Z",
     "iopub.status.busy": "2023-11-12T00:47:12.631825Z",
     "iopub.status.idle": "2023-11-12T00:47:12.649446Z",
     "shell.execute_reply": "2023-11-12T00:47:12.649008Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dense.compile(loss=\"mse\",optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76677060",
   "metadata": {},
   "source": [
    "Finally, we train the model using the `fit` function. Similarly to scikit-learn, Keras' `fit` function takes the training data as input. It also requires the number of epochs (iterations through the training dataset) to run. We will train all of our neural network models for 25 epochs. The method returns a logging object that contains the evolution of the loss over the epochs. Save this to `history_dense`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeee454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:12.651762Z",
     "iopub.status.busy": "2023-11-12T00:47:12.651587Z",
     "iopub.status.idle": "2023-11-12T00:47:18.004984Z",
     "shell.execute_reply": "2023-11-12T00:47:18.004607Z"
    }
   },
   "outputs": [],
   "source": [
    "train_epochs = 25\n",
    "history_dense = model_dense.fit(Xtrain_e, ytrain_e,epochs=train_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e3fe5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 9. Train a simple recurrent neural network\n",
    "\n",
    "Next we will build a neural network with simple recurrent units. The schematic is identical to the one shown in section 8, except that now the units in the hidden layer will be recurrent neurons. In Keras, this is specified as a sequential model with two layers. The `Flatten` layer of the dense network is no longer required. Instead, the first layer is of type `SimpleRNN`. The constructor for `SimpleRNN` takes the number of recurrent units (5) and the shape of the input vector (`input_shape=(Np,1)`). The second layer is the same output layer as was used for the dense network.\n",
    "\n",
    "```python \n",
    "model_simprnn = Sequential([\n",
    "    SimpleRNN(5,input_shape=(Np,1)),\n",
    "    Dense(Nf)\n",
    "])\n",
    "```\n",
    "Create this model, then compile and train it with the same arguments as in part 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0379b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:18.006637Z",
     "iopub.status.busy": "2023-11-12T00:47:18.006414Z",
     "iopub.status.idle": "2023-11-12T00:47:26.520053Z",
     "shell.execute_reply": "2023-11-12T00:47:26.519692Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_simprnn = ...\n",
    "model_simprnn.compile(...)\n",
    "history_simprnn = model_simprnn.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ae0ce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b70613",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 10. Train an LSTM neural network\n",
    "\n",
    "Finally we will create a neural network with LSTM units. The code is identical to the Simple RNN case, except that instad of a `SimpleRNN` layer, we use an `LSTM` layer. Create, compile, and train this model. Save the model to `model_lstm` and its training history to `history_lstm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddf04f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:26.535938Z",
     "iopub.status.busy": "2023-11-12T00:47:26.535788Z",
     "iopub.status.idle": "2023-11-12T00:47:44.069216Z",
     "shell.execute_reply": "2023-11-12T00:47:44.068746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_lstm = ...\n",
    "model_lstm.compile(...)\n",
    "history_lstm = model_lstm.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836d89c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a173c2",
   "metadata": {},
   "source": [
    "# 11. Forecast\n",
    "\n",
    "Use the `predict` method of the model objects to generate forecasts for the test data. The input to this function is the \"extended\" version of the testing data `Xtest_e`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163def01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:44.079664Z",
     "iopub.status.busy": "2023-11-12T00:47:44.079350Z",
     "iopub.status.idle": "2023-11-12T00:47:44.799372Z",
     "shell.execute_reply": "2023-11-12T00:47:44.798924Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat_dense   = model_dense.predict(Xtest_e)\n",
    "yhat_simprnn = ...\n",
    "yhat_lstm    = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06972d6b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04f064",
   "metadata": {},
   "source": [
    "# 12. Plots\n",
    "\n",
    "### 12.1 Training histories\n",
    "\n",
    "The loss after each of the training epochs is contained in the history object, and is plotted below. Notice that the LSTM model concludes the training with the lowest loss value, while the dense and Simple RNN models have similar values of final training loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5afc1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:44.822006Z",
     "iopub.status.busy": "2023-11-12T00:47:44.821761Z",
     "iopub.status.idle": "2023-11-12T00:47:44.952456Z",
     "shell.execute_reply": "2023-11-12T00:47:44.951971Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(history_dense.history['loss'], 'bo-',label='Dense')\n",
    "plt.plot(history_simprnn.history['loss'], 'mo-',label='Simple RNN')\n",
    "plt.plot(history_lstm.history['loss'], 'co-',label='LSTM')\n",
    "plt.legend()\n",
    "plt.grid(':')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624b84c",
   "metadata": {},
   "source": [
    "### 12.2. A sample prediction\n",
    "\n",
    "To plot the forecast, we will first use the `scaler` object to return the data to its original scale (in vehicles per hour, or vph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a529094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:44.954399Z",
     "iopub.status.busy": "2023-11-12T00:47:44.954235Z",
     "iopub.status.idle": "2023-11-12T00:47:44.958105Z",
     "shell.execute_reply": "2023-11-12T00:47:44.957675Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtest_vph = scaler.inverse_transform(Xtest)\n",
    "ytest_vph = scaler.inverse_transform(ytest)\n",
    "yhat_dense_vph = scaler.inverse_transform(yhat_dense)\n",
    "yhat_simprnn_vph = scaler.inverse_transform(yhat_simprnn)\n",
    "yhat_lstm_vph = scaler.inverse_transform(yhat_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8892c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:44.959781Z",
     "iopub.status.busy": "2023-11-12T00:47:44.959616Z",
     "iopub.status.idle": "2023-11-12T00:47:45.117167Z",
     "shell.execute_reply": "2023-11-12T00:47:45.116598Z"
    }
   },
   "outputs": [],
   "source": [
    "i=500\n",
    "tx = np.arange(-Np,0)+1\n",
    "ty = np.arange(Nf)+1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5)) \n",
    "ax.plot(tx,Xtest_vph[i],'ro-', lw = 3,label='past 6 hours') \n",
    "ax.plot(ty,ytest_vph[i] ,'go-', lw = 3,label='future 24 hours') \n",
    "ax.plot(ty,yhat_dense_vph[i],'bo-', markersize=3, lw = 1, label='Dense') \n",
    "ax.plot(ty,yhat_simprnn_vph[i],'mo-', markersize=3, lw = 1, label='Simple RNN') \n",
    "ax.plot(ty,yhat_lstm_vph[i],'co-', markersize=3, lw =1, label='LSTM') \n",
    "ax.grid(':')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d063cfb",
   "metadata": {},
   "source": [
    "# 13. Compute performance\n",
    "\n",
    "We measure the performance of the models with their mean absolute errors. Write a function that computes the MAE between two arrays. Apply it to the unscaled versions of the three model predictions and the test outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712647c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:45.119453Z",
     "iopub.status.busy": "2023-11-12T00:47:45.119257Z",
     "iopub.status.idle": "2023-11-12T00:47:45.123905Z",
     "shell.execute_reply": "2023-11-12T00:47:45.123287Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_mae(yhat,ytest):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c4b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T00:47:45.126406Z",
     "iopub.status.busy": "2023-11-12T00:47:45.125961Z",
     "iopub.status.idle": "2023-11-12T00:47:45.131958Z",
     "shell.execute_reply": "2023-11-12T00:47:45.131461Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mae_dense = compute_mae(yhat_dense,ytest_vph)\n",
    "mae_simprnn = compute_mae(yhat_simprnn_vph,ytest_vph)\n",
    "mae_lstm = compute_mae(yhat_lstm_vph,ytest_vph)\n",
    "\n",
    "mae_dense, mae_simprnn, mae_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037ee49",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aedf99",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ade1de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcd7b7",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0": {
     "name": "q0",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (rawdata is not None) and rawdata.shape[0]==13980\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ('DateAndTimeTS' in rawdata.columns) and (type(rawdata['DateAndTimeTS'][0])==pd._libs.tslibs.timestamps.Timestamp)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model_lstm.get_config()['layers'][0]['class_name']=='InputLayer' and \\\n... model_lstm.get_config()['layers'][0]['config']['batch_input_shape']==(None, 6, 1) and \\\n... model_lstm.get_config()['layers'][1]['class_name']=='LSTM' and \\\n... model_lstm.get_config()['layers'][1]['config']['batch_input_shape']==(None, 6, 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> yhat_dense.shape==(2766, 24) and yhat_simprnn.shape==(2766, 24) and yhat_lstm.shape==(2766, 24)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(yhat_dense[:5,:5],np.array([[0.4388529 , 0.64404047, 0.6783319 , 0.73585904, 0.84136415],\n...        [0.97280717, 0.9306428 , 0.79587066, 0.78927994, 0.8791541 ],\n...        [1.013487  , 0.99908984, 0.92824966, 0.9273282 , 0.9662    ],\n...        [0.9781668 , 1.0277343 , 1.0271584 , 0.99955845, 0.94756854],\n...        [1.0915511 , 1.1103691 , 1.1362342 , 1.1358428 , 1.0763679 ]]),1e-2))\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(yhat_simprnn[:5,:5],np.array([[0.72212905, 0.96939445, 1.0435158 , 1.0437351 , 1.0022954 ],\n...        [0.89051837, 0.9253676 , 0.8325755 , 0.77615154, 0.7460695 ],\n...        [0.9098348 , 0.8963374 , 0.82915664, 0.8337238 , 0.8794229 ],\n...        [0.85661846, 0.83173513, 0.811392  , 0.8633232 , 0.9311729 ],\n...        [0.86052257, 0.83580565, 0.83853936, 0.87950665, 0.9114979 ]]),1e-2))\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(yhat_lstm[:5,:5],np.array([[0.51328224, 0.8539859 , 1.006242  , 1.0394508 , 1.0034708 ],\n...        [0.76915145, 1.0135615 , 1.0681678 , 1.0212207 , 0.92616224],\n...        [0.91571105, 1.0441518 , 1.0261366 , 0.9555544 , 0.8570435 ],\n...        [1.0291822 , 1.0403317 , 0.9755738 , 0.92160684, 0.85469663],\n...        [0.88564634, 0.81100476, 0.7573972 , 0.7753442 , 0.8072547 ]]),1e-2))\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q13": {
     "name": "q13",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(mae_dense,1.0000951034154313,1e-2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(mae_simprnn,0.2985688091508766,1e-2)\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(mae_lstm,0.28611520439895655,1e-2)\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (data1 is not None) and (data1.index.name=='DateAndTimeTS') and (type(data1.index[0])==pd._libs.tslibs.timestamps.Timestamp)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (len(data2.columns)==1) and (data2.columns[0]=='Flow')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> data_train.shape==(11184, 1) and data_test.shape==(2796, 1) and data_train.index[0]==pd.Timestamp('2018-01-01 00:00:00') and data_train.index[-1]==pd.Timestamp('2019-06-26 00:00:00') and data_test.index[0]==pd.Timestamp('2019-06-26 01:00:00') and data_test.index[-1]==pd.Timestamp('2019-10-26 06:00:00') \nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(scaler.mean_[0],7218.13796495,1e-1) and np.isclose(scaler.scale_[0],2959.82974674,1e-1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> data_train_scaled.shape==(11184, 1) and np.all(np.isclose(data_train_scaled[:10,0],np.array([-1.2099135 , -1.10247489, -1.26836281, -1.48932146, -1.54033791, -1.59203007, -1.43560216, -1.32444711, -1.26971424, -0.96496698]),1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> data_test_scaled.shape==(2796, 1) and np.all(np.isclose(data_test_scaled[:10,0],np.array([-1.57479935, -1.58662436, -1.53358076, -1.35721927, -0.83624336,0.17732845,  0.86520586,  1.10339523,  0.89899158,  0.75878082]),1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xtrain.shape==(11154, 6) and ytrain.shape==(11154, 24) and Xtest.shape==(2766, 6) and ytest.shape==(2766, 24)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(Xtrain[:3,:],np.array([[-1.2099135 , -1.10247489, -1.26836281, -1.48932146, -1.54033791,-1.59203007],\n...        [-1.10247489, -1.26836281, -1.48932146, -1.54033791, -1.59203007,-1.43560216],\n...        [-1.26836281, -1.48932146, -1.54033791, -1.59203007, -1.43560216,-1.32444711]]),1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(ytrain[:3,:6],np.array([[-1.43560216, -1.32444711, -1.26971424, -0.96496698, -0.74434618,-0.36087818],\n...        [-1.32444711, -1.26971424, -0.96496698, -0.74434618, -0.36087818,-0.04160306],\n...        [-1.26971424, -0.96496698, -0.74434618, -0.36087818, -0.04160306,-0.02268305]]),1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xtrain_e.shape==(11154, 6, 1) and ytrain_e.shape==(11154, 24, 1) and Xtest_e.shape==(2766, 6, 1) and ytest_e.shape==(2766, 24, 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(Xtrain_e[:,:,0]==Xtrain) and np.all(ytrain_e[:,:,0]==ytrain) and np.all(Xtest_e[:,:,0]==Xtest) and np.all(ytest_e[:,:,0]==ytest)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model_dense.get_config()['layers'][0]['class_name']=='Flatten' and \\\n... model_dense.get_config()['layers'][1]['class_name']=='Dense' and \\\n... model_dense.get_config()['layers'][1]['config']['units']==5 and \\\n... model_dense.get_config()['layers'][1]['config']['activation']=='relu' and \\\n... model_dense.get_config()['layers'][2]['class_name'] and \\\n... model_dense.get_config()['layers'][2]['config']['units']==24 and \\\n... model_dense.get_config()['layers'][2]['config']['activation']=='linear'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model_simprnn.get_config()['layers'][0]['class_name']=='InputLayer' and \\\n... model_simprnn.get_config()['layers'][0]['config']['batch_input_shape']==(None, 6, 1) and \\\n... model_simprnn.get_config()['layers'][1]['class_name']=='SimpleRNN' and \\\n... model_simprnn.get_config()['layers'][1]['config']['batch_input_shape']==(None, 6, 1) and \\\n... model_simprnn.get_config()['layers'][2]['class_name']=='Dense' and \\\n... model_simprnn.get_config()['layers'][2]['config']['units']==24 \nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(model_simprnn.get_weights()[0],np.array([[-1.1073184 ,  0.95952076, -0.7785383 ,  0.77206063, -0.00925372]]),1e-3))\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
